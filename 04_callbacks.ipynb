{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af897c1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#192015; color:#7fa637; padding:12px; border-radius:8px; max-width:80%; width:auto; margin:0 auto;\">\n",
    "\n",
    "![nvmath-python](_assets/nvmath_head_panel@0.25x.png)\n",
    "\n",
    "<p style=\"font-size:0.85em; margin-top:8px;\">\n",
    "Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES<br>\n",
    "SPDX-License-Identifier: BSD-3-Clause\n",
    "</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1067bad8",
   "metadata": {},
   "source": [
    "# Getting started with nvmath-python: FFT callbacks\n",
    "\n",
    "In this tutorial we provide basic 101 about **nvmath-python**, how it fits in and plays with an existing scientific computing ecosystem in Python and what makes it a useful addition for this ecosystem. \n",
    "<div class=\"alert alert-box alert-info\">\n",
    "    To use this notebook you will need a computer equipped with NVIDIA GPU as well as an environment with properly installed Python libraries and (optionally) CUDA Toolkit. Please refer to the nvmath-python documentation for getting familiar with <a href=\"https://docs.nvidia.com/cuda/nvmath-python/0.2.1/installation.html#install-nvmath-python\">installation options</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d34b2",
   "metadata": {},
   "source": [
    "This section focuses on FFT callbacks, which are custom Python functions *just-in-time* compiled into *intermediate representation* and provided as inputs to nvmath-python FFT as *prolog* or *epilog* arguments. \n",
    "\n",
    "But first, let's borrow the benchmarking helper function we created in the previous section to continue performance experiments with FFT implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupyx as cpx\n",
    "\n",
    "\n",
    "# Helper function to benchmark two implementations F and (optionally) F_alternative\n",
    "# When F_alternative is provided, in addition to raw performance numbers (seconds)\n",
    "# speedup of F relative to F_alternative is reported\n",
    "def benchmark(\n",
    "    F, F_name=\"Implementation\", F_alternative=None, F_alternative_name=\"Alternative implementation\", n_repeat=10, n_warmup=1\n",
    "):\n",
    "    timing = cpx.profiler.benchmark(F, n_repeat=n_repeat, n_warmup=n_warmup)  # warm-up + repeated runs\n",
    "    perf = np.min(timing.gpu_times)  # best time from repeated runs\n",
    "    print(f\"{F_name} performance = {perf:0.4f} sec\")\n",
    "\n",
    "    if F_alternative is not None:\n",
    "        timing_alt = cpx.profiler.benchmark(F_alternative, n_repeat=n_repeat, n_warmup=n_warmup)\n",
    "        perf_alt = np.min(timing_alt.gpu_times)\n",
    "        print(f\"{F_alternative_name} performance = {perf_alt:0.4f} sec\")\n",
    "        print(f\"Speedup = {perf_alt / perf:0.4f}x\")\n",
    "    else:\n",
    "        perf_alt = None\n",
    "\n",
    "    return perf, perf_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223f8f3",
   "metadata": {},
   "source": [
    "In this notebook we touch upon a typical image processing problem known as the Gaussian filter. The following block implements the Gaussina filter using `scipy.ndimage` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90be84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "asset_path = \"./_assets/\"\n",
    "img = Image.open(asset_path + \"dog.jpg\").convert(\"L\")\n",
    "original_image = np.array(img, dtype=np.float32) / 255.0\n",
    "\n",
    "sigma_value = 20.0  # Filter size\n",
    "\n",
    "filtered_image_scipy = gaussian_filter(original_image, sigma=sigma_value)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(filtered_image_scipy, cmap=\"gray\")\n",
    "plt.title(\"Filtered (SciPy)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78383cf",
   "metadata": {},
   "source": [
    "Next, we will implement the Gaussian filter using CuPy's 2D forward and inverse FFT along with the filter (frequency response) applied in the frequency domain.\n",
    "\n",
    "The frequency response is implemented in the `create_gaussian_kernel_2s()` function, which relies on the fact that the Fourier transform on a Gaussian distribution in the *spatial domain* corresponds to another Gaussian distribution in the *frequency domain* (and vice versa).\n",
    "\n",
    "Please note that the original image is loaded as a numpy array in CPU memory space. To perform computation in GPU memory space, we explicitly convert the image to CuPy array, perform forward and inverse FFT transforms, and convert the final image back to CPU memory space for visualization with `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd444cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath  # Preload CTK libraries installed from wheels for CuPy\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "def create_gaussian_filter(shape, sigma):\n",
    "    \"\"\"\n",
    "    Create the Gaussian filter's frequency response for R2C FFT.\n",
    "    For R2C FFT, we only need the positive frequencies in the last dimension.\n",
    "    \"\"\"\n",
    "    h, w = shape\n",
    "\n",
    "    # frequency coordinates in cycles/sample for each axis (CuPy)\n",
    "    fy = cp.fft.fftfreq(h)[:, None]  # column vector\n",
    "    fx = cp.fft.rfftfreq(w)[None, :]  # row vector for R2C (only positive frequencies)\n",
    "\n",
    "    # Continuous Fourier transform of a Gaussian\n",
    "    # g(x)=exp(-x^2/(2*sigma^2)) is another Gaussian\n",
    "    # G(f) = exp(-2 * pi^2 * sigma^2 * f^2). For 2D separable:\n",
    "    # H(fx,fy) = exp(-2 * pi^2 * sigma^2 * (fx^2 + fy^2)).\n",
    "    h_fx_fy = cp.exp(-2.0 * cp.pi * cp.pi * sigma * sigma * (fx * fx + fy * fy))\n",
    "    return h_fx_fy\n",
    "\n",
    "\n",
    "def gaussian_filter_cupy(image, sigma, clear_cache=True):\n",
    "    \"\"\"\n",
    "    Apply Gaussian filter using CuPy R2C/C2R FFT.\n",
    "    \"\"\"\n",
    "    if clear_cache:\n",
    "        cp.fft.config.clear_plan_cache()  # Clear CuPy FFT cache to ensure clean FFT benchmarking\n",
    "    filter = create_gaussian_filter(image.shape, sigma)\n",
    "    image_fft = cp.fft.rfft2(image)  # Real to complex FFT\n",
    "    filtered = cp.fft.irfft2(image_fft * filter, s=image.shape)  # Complex to real FFT\n",
    "    return filtered\n",
    "\n",
    "image_gpu = cp.asarray(original_image, dtype=cp.float32)\n",
    "filtered_image_cupy = gaussian_filter_cupy(image_gpu, sigma_value)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cp.asnumpy(filtered_image_cupy), cmap=\"gray\")\n",
    "plt.title(\"Filtered (CuPy)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de5f6e",
   "metadata": {},
   "source": [
    "We implement the Gaussian filter using nvmath-python forward and inverse FFTs. Note that `create_gaussian_kernel_2d` is now part of the `epilog_impl` function compiled to the intermediate representation (LTO-IR) and supplied to the forward FFT as an *epilog*. This allows fusing the epilog with FFT, which improves the *arithmetic intensity* of the composite operation. However, you will pay a one-time cost related to the JIT compilation overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a611720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_filter_nvmath(image, sigma):\n",
    "    \"\"\"\n",
    "    Apply Gaussian filter using nvmath FFT helper functions on GPU with epilog.\n",
    "\n",
    "    This function uses nvmath.fft.rfft / nvmath.fft.irfft with an epilog to perform\n",
    "    the gaussian kernel multiplication directly within the FFT operation.\n",
    "    The input is moved to GPU as a CuPy real array and results are returned as NumPy array.\n",
    "    \"\"\"\n",
    "    wh = image.shape[0] * image.shape[1]\n",
    "\n",
    "    # Gaussian kernel on GPU for R2C FFT\n",
    "    filter = create_gaussian_filter(image.shape, sigma)\n",
    "\n",
    "    # Define epilog function for gaussian kernel multiplication\n",
    "    def epilog_impl(data_out, offset, data, filter_data, unused):\n",
    "        \"\"\"Epilog function to multiply FFT data with gaussian kernel.\"\"\"\n",
    "        data_out[offset] = data * filter_data[offset] / wh  # Normalize by the image area\n",
    "\n",
    "    # Compile the epilog to LTO-IR\n",
    "    epilog = nvmath.fft.compile_epilog(epilog_impl, \"complex64\", \"complex64\")\n",
    "\n",
    "    # Compute R2C FFT using nvmath with epilog to apply gaussian kernel multiplication\n",
    "    image_fft = nvmath.fft.rfft(image, epilog={\"ltoir\": epilog, \"data\": filter.data.ptr})\n",
    "\n",
    "    # Inverse C2R FFT using nvmath\n",
    "    filtered = nvmath.fft.irfft(image_fft)\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "image_gpu = cp.asarray(original_image, dtype=cp.float32)\n",
    "filtered_image_nvmath = gaussian_filter_nvmath(image_gpu, sigma_value)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image, cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cp.asnumpy(filtered_image_cupy), cmap=\"gray\")\n",
    "plt.title(\"Filtered (nvmath-python)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57095f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    lambda: gaussian_filter_nvmath(image_gpu, sigma_value),\n",
    "    \"nvmath-python API\",\n",
    "    lambda: gaussian_filter_cupy(image_gpu, sigma_value),\n",
    "    \"CuPy API\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1115d2e1",
   "metadata": {},
   "source": [
    "The nvmath-python provides both *stateless* and *stateful* APIs for FFT so that you can separate the *planning* (including expensive JIT compilation of the epilog) and *exefution* phases and amortize the *planning* cost through multiple executions.\n",
    "\n",
    "To illustrate this let us consider the problem of applying the Gaussian filter to multiple images in a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69b87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "images_gpu = [image_gpu] * batch_size\n",
    "\n",
    "# Display the array of identical images\n",
    "plt.figure(figsize=(30, 3))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(1, batch_size, i + 1)\n",
    "    plt.imshow(cp.asnumpy(images_gpu[i]), cmap=\"gray\")\n",
    "    plt.title(f\"Copy {i + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b589fc2",
   "metadata": {},
   "source": [
    "First, we create a reference implementation of the batched Gaussian filter using pure CuPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702a7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_cupy(images_gpu, sigma_value):\n",
    "    \"\"\"\n",
    "    Process a batch of images using CuPy.\n",
    "    \"\"\"\n",
    "    # Clear CuPy FFT cache to ensure clean FFT benchmarking during multiple repetitions (n_repeat > 1)\n",
    "    # For fair comparison, we do not want the planning cost of the first call to be ignored\n",
    "    cp.fft.config.clear_plan_cache()\n",
    "    filtered_images = []\n",
    "    for i in range(len(images_gpu)):\n",
    "        filtered_images.append(gaussian_filter_cupy(images_gpu[i], sigma_value, clear_cache=False))\n",
    "    return filtered_images\n",
    "\n",
    "\n",
    "filtered_images = process_batch_cupy(images_gpu, sigma_value)\n",
    "\n",
    "plt.figure(figsize=(30, 3))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(1, batch_size, i + 1)\n",
    "    plt.imshow(cp.asnumpy(filtered_images[i]), cmap=\"gray\")\n",
    "    plt.title(f\"Filtered {i + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90d189",
   "metadata": {},
   "source": [
    "Next, we implement the same logic using nvmath-python's stateful API. We create two FFT objects, one for the forward FFT plan, which includes a compiled epilog, and another is for the inverse FFT plan. It is essential to create two objects because a single object can only have one plan. Finally we apply the filter to each image in the batch through a series of forward and inverse FFTs. Please also note that `reset_operand()` method must be properly used to update operands for a chained FFT operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6549247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_nvmath(images_gpu, sigma):\n",
    "    \"\"\"\n",
    "    Process a batch of images using nvmath with stateful API.\n",
    "\n",
    "    This function uses the stateful API to create a persistent FFT plan\n",
    "    and epilog that can be reused across multiple images in the batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the gaussian kernel once for the batch (R2C format)\n",
    "    filter = create_gaussian_filter(images_gpu[0].shape, sigma).astype(cp.complex64)\n",
    "    wh = images_gpu[0].shape[0] * images_gpu[0].shape[1]\n",
    "\n",
    "\n",
    "    # Define epilog function for gaussian kernel multiplication\n",
    "    def epilog_impl(data_out, offset, data, filter_data, unused):\n",
    "        \"\"\"Epilog implementation.\"\"\"\n",
    "        data_out[offset] = data * filter_data[offset] / wh  # Normalize by the image area\n",
    "\n",
    "\n",
    "    # Compile the epilog to LTO-IR once\n",
    "    epilog = nvmath.fft.compile_epilog(epilog_impl, \"complex64\", \"complex64\")\n",
    "\n",
    "\n",
    "    def convolve_gpu(fft, ifft, image_gpu):\n",
    "        fft.reset_operand(image_gpu)\n",
    "        image_fft = fft.execute(direction=nvmath.fft.FFTDirection.FORWARD)\n",
    "        ifft.reset_operand(image_fft)\n",
    "        image_ifft = ifft.execute(direction=nvmath.fft.FFTDirection.INVERSE)\n",
    "        return image_ifft\n",
    "\n",
    "\n",
    "    image_gpu = images_gpu[0]  # Real input for R2C FFT\n",
    "    image_fft = cp.empty((image_gpu.shape[0], image_gpu.shape[1] // 2 + 1), dtype=cp.complex64)\n",
    "\n",
    "    with (\n",
    "        nvmath.fft.FFT(image_gpu) as fft,\n",
    "        nvmath.fft.FFT(image_fft, options={\"fft_type\": \"C2R\"}) as ifft,\n",
    "    ):\n",
    "        # Two plans are created, one for the forward R2C FFT with an epilog\n",
    "        # and another for the inverse C2R FFT\n",
    "        fft.plan(epilog={\"ltoir\": epilog, \"data\": filter.data.ptr})\n",
    "        ifft.plan()\n",
    "\n",
    "        # Process each image in the batch\n",
    "        filtered_images = []\n",
    "        for i in range(len(images_gpu)):\n",
    "            filtered_images.append(convolve_gpu(fft, ifft, images_gpu[i]))\n",
    "    return filtered_images\n",
    "\n",
    "\n",
    "# Process the batch using nvmath stateful API\n",
    "filtered_images_nvmath = process_batch_nvmath(images_gpu, sigma_value)\n",
    "\n",
    "plt.figure(figsize=(30, 3))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(1, batch_size, i + 1)\n",
    "    plt.imshow(cp.asnumpy(filtered_images_nvmath[i]), cmap=\"gray\")\n",
    "    plt.title(f\"Filtered {i + 1}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa2378",
   "metadata": {},
   "source": [
    "Finally, let us take a look at the performance. Please remember, CuPy inherently performs FFT plans *caching* so that a subsequent calls with images of the same shape and dtype will avoid re-planning overhead. With nvmath-python we avoid re-planning explicitly by using *stateful* APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear CuPy FFT cache to ensure clean FFT operations\n",
    "cp.fft.config.clear_plan_cache()\n",
    "benchmark(\n",
    "    lambda: process_batch_nvmath(images_gpu, sigma_value),\n",
    "    \"nvmath-python stateful API\",\n",
    "    lambda: process_batch_cupy(images_gpu, sigma_value),\n",
    "    \"CuPy API\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d79f92",
   "metadata": {},
   "source": [
    "Let us drill down how much each phase costs in each of the libraries. For CuPy the cost of the very first call, where FFT planning and plan caching is performed, will be very different from the subsequent calls, where the cached plan is reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827de35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cupy_first_call(image_gpu, sigma_value):\n",
    "    # To emulate the cost of the first call we need to clear the cache\n",
    "    cp.fft.config.clear_plan_cache()\n",
    "    gaussian_filter_cupy(image_gpu, sigma_value, clear_cache=False)\n",
    "\n",
    "def process_cupy_subsequent_call(image_gpu, sigma_value):\n",
    "    # With n_repeat > 1 the first call cost will be ignored\n",
    "    gaussian_filter_cupy(image_gpu, sigma_value, clear_cache=False)\n",
    "\n",
    "perf_cupy_subsequent_call, perf_cupy_first_call = benchmark(\n",
    "    lambda: process_cupy_subsequent_call(image_gpu, sigma_value),\n",
    "    \"CuPy subsequent calls\",\n",
    "    lambda: process_cupy_first_call(image_gpu, sigma_value),\n",
    "    \"CuPy first call\",\n",
    ")\n",
    "\n",
    "perf_cupy_planning = perf_cupy_first_call - perf_cupy_subsequent_call\n",
    "print(f\"Estimated CuPy planning cost = {perf_cupy_planning:0.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf370d",
   "metadata": {},
   "source": [
    "Similarly, let's atomize the costs within nvmath-python implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the gaussian kernel once for the batch (R2C format)\n",
    "filter = create_gaussian_filter(image_gpu.shape, sigma_value).astype(cp.complex64)\n",
    "wh = image_gpu.shape[0] * image_gpu.shape[1]\n",
    "\n",
    "# Define epilog function for gaussian kernel multiplication\n",
    "def epilog_impl(data_out, offset, data, filter_data, unused):\n",
    "    \"\"\"Epilog implementation.\"\"\"\n",
    "    data_out[offset] = data * filter_data[offset] / wh  # Normalize by the image area\n",
    "\n",
    "# Compile the epilog to LTO-IR once\n",
    "def compile_epilog():\n",
    "    return nvmath.fft.compile_epilog(epilog_impl, \"complex64\", \"complex64\")\n",
    "\n",
    "def forward_fft_execute(fft, image_gpu):\n",
    "    fft.reset_operand(image_gpu)\n",
    "    return fft.execute(direction=nvmath.fft.FFTDirection.FORWARD)\n",
    "\n",
    "def inverse_fft_execute(ifft, image_gpu):\n",
    "    ifft.reset_operand(image_gpu)\n",
    "    return ifft.execute(direction=nvmath.fft.FFTDirection.INVERSE)\n",
    "\n",
    "def forward_fft_plan(image_gpu, epilog):\n",
    "    fft = nvmath.fft.FFT(image_gpu)\n",
    "    fft.plan(epilog={\"ltoir\": epilog, \"data\": filter.data.ptr})\n",
    "    return fft\n",
    "\n",
    "def inverse_fft_plan(c2r_output):\n",
    "    ifft = nvmath.fft.FFT(c2r_output, options={\"fft_type\": \"C2R\"})\n",
    "    ifft.plan()\n",
    "    return ifft\n",
    "\n",
    "epilog = compile_epilog()\n",
    "c2r_output = cp.empty((image_gpu.shape[0], image_gpu.shape[1] // 2 + 1), dtype=cp.complex64)\n",
    "fft = forward_fft_plan(image_gpu, epilog)\n",
    "ifft = inverse_fft_plan(c2r_output)\n",
    "fft_image = forward_fft_execute(fft, image_gpu)\n",
    "filtered_image = inverse_fft_execute(ifft, fft_image)\n",
    "\n",
    "print(image_gpu.sum())\n",
    "print(filtered_image.sum())\n",
    "\n",
    "perf_compile_epilog = cpx.profiler.benchmark(lambda: compile_epilog(), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "perf_forward_fft_plan = cpx.profiler.benchmark(lambda: forward_fft_plan(image_gpu, epilog), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "perf_inverse_fft_plan = cpx.profiler.benchmark(lambda: inverse_fft_plan(c2r_output), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "perf_forward_fft_execute = cpx.profiler.benchmark(lambda: forward_fft_execute(fft, image_gpu), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "perf_inverse_fft_execute = cpx.profiler.benchmark(lambda: inverse_fft_execute(ifft, fft_image), n_repeat=5, n_warmup=1).gpu_times.min()\n",
    "\n",
    "print(f\"Compilation cost = {perf_compile_epilog:0.4f} sec\")\n",
    "print(f\"Forward FFT plan cost = {perf_forward_fft_plan:0.4f} sec\")\n",
    "print(f\"Inverse FFT plan cost = {perf_inverse_fft_plan:0.4f} sec\")\n",
    "print(f\"Forward FFT execute cost = {perf_forward_fft_execute:0.4f} sec\")\n",
    "print(f\"Inverse FFT execute cost = {perf_inverse_fft_execute:0.4f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4fc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CuPy and nvmath-python cost per image for batch sizes 1 to 16\n",
    "batch_sizes = np.arange(1, 17)\n",
    "\n",
    "# CuPy: First image includes planning + execution, subsequent images are execution only\n",
    "cupy_costs_per_image = [(perf_cupy_first_call + (n - 1) * perf_cupy_subsequent_call) / n for n in batch_sizes]\n",
    "\n",
    "# nvmath-python: First image includes compilation + planning + execution, subsequent images are execution only\n",
    "nvmath_costs_per_image = [(perf_compile_epilog + perf_forward_fft_plan + perf_inverse_fft_plan) / n + perf_forward_fft_execute + perf_inverse_fft_execute for n in batch_sizes]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(batch_sizes, cupy_costs_per_image, marker='o', linewidth=2, markersize=8, color='darkgreen', label='CuPy')\n",
    "plt.plot(batch_sizes, nvmath_costs_per_image, marker='s', linewidth=2, markersize=8, color='#76b900', label='nvmath-python')\n",
    "plt.xlabel('Number of Images', fontsize=12)\n",
    "plt.ylabel('Cost per Image (seconds)', fontsize=12)\n",
    "plt.title('Cost per Image Comparison: CuPy vs nvmath-python\\n(First image includes planning/compilation + execution, subsequent images execution only)', fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(batch_sizes)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(\"CuPy Cost Breakdown:\")\n",
    "print(f\"  Planning cost: {perf_cupy_planning:.4f} sec\")\n",
    "print(f\"  Execution cost (per image): {perf_cupy_subsequent_call:.4f} sec\")\n",
    "print(f\"  First image total: {perf_cupy_first_call:.4f} sec\")\n",
    "\n",
    "print(\"\\nnvmath-python Cost Breakdown:\")\n",
    "print(f\"  Compilation cost: {perf_compile_epilog:.4f} sec\")\n",
    "print(f\"  Forward FFT plan cost: {perf_forward_fft_plan:.4f} sec\")\n",
    "print(f\"  Inverse FFT plan cost: {perf_inverse_fft_plan:.4f} sec\")\n",
    "print(f\"  Execution cost (per image): {perf_forward_fft_execute + perf_inverse_fft_execute:.4f} sec\")\n",
    "print(f\"  First image total: {perf_compile_epilog + perf_forward_fft_plan + perf_inverse_fft_plan + perf_forward_fft_execute + perf_inverse_fft_execute:.4f} sec\")\n",
    "\n",
    "print(\"\\nCost per image comparison:\")\n",
    "for n in [1, 4, 8, 16]:\n",
    "    cupy_per_img = cupy_costs_per_image[n-1]\n",
    "    nvmath_per_img = nvmath_costs_per_image[n-1]\n",
    "    speedup = cupy_per_img / nvmath_per_img\n",
    "    print(f\"  {n:2d} images: CuPy={cupy_per_img:.4f} sec/img, nvmath={nvmath_per_img:.4f} sec/img, speedup={speedup:.2f}x\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways_callbacks",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#76B900; color:#ffffff; padding:12px; border-radius:8px; max-width:80%; width:auto; margin:0 auto;\">\n",
    "<h3 style=\"margin-top:0; color:#ffffff\">Takeaways</h3>\n",
    "\n",
    "- FFT callbacks allow custom Python functions to be JIT-compiled and fused with FFT kernels as prolog or epilog operations.\n",
    "- JIT compilation overhead is a one-time cost that can be amortized across multiple executions.\n",
    "- CuPy has a built-in plan caching mechanism allowing to amortize initial planning cost across executions.\n",
    "- nvmath-python stateful API amortize compilation and planning costs as well as avoid plan cache retrival cost in subsequent executions.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
