{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671193a4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#192015; color:#7fa637; padding:12px; border-radius:8px; max-width:80%; width:auto; margin:0 auto;\">\n",
    "\n",
    "![nvmath-python](_assets/nvmath_head_panel@0.25x.png)\n",
    "\n",
    "<p style=\"font-size:0.85em; margin-top:8px;\">\n",
    "Copyright (c) 2025, NVIDIA CORPORATION & AFFILIATES<br>\n",
    "SPDX-License-Identifier: BSD-3-Clause\n",
    "</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e40334",
   "metadata": {},
   "source": [
    "# Getting started with nvmath-python: device APIs\n",
    "\n",
    "In this tutorial we provide basic 101 about **nvmath-python**, how it fits in and \n",
    "plays with an existing scientific computing ecosystem in Python and what makes it \n",
    "a useful addition for this ecosystem. \n",
    "\n",
    "<div class=\"alert alert-box alert-info\">\n",
    "    To use this notebook you will need a computer equipped with NVIDIA GPU as well \n",
    "    as an environment with properly installed Python libraries and (optionally) \n",
    "    CUDA Toolkit. Please refer to the nvmath-python documentation for getting \n",
    "    familiar with <a href=\"https://docs.nvidia.com/cuda/nvmath-python/0.2.1/installation.html#install-nvmath-python\">installation options</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21497b",
   "metadata": {},
   "source": [
    "This section demonstrates the use of nvmath-python from within custom kernels \n",
    "written using *numba-cuda*. The problem being solved is Monte Carlo stock price \n",
    "simulation with *Geometric Brownian Motion* (GBM) model.\n",
    "\n",
    "But first, let's borrow the benchmarking helper function we created in the previous \n",
    "section to continue performance experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aed9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupyx as cpx\n",
    "\n",
    "\n",
    "# Helper function to benchmark two implementations F and (optionally) F_alternative\n",
    "# When F_alternative is provided, in addition to raw performance numbers (seconds)\n",
    "# speedup of F relative to F_alternative is reported\n",
    "def benchmark(\n",
    "    F, F_name=\"Implementation\", F_alternative=None, F_alternative_name=\"Alternative implementation\", n_repeat=10, n_warmup=1\n",
    "):\n",
    "    # warm-up + repeated runs\n",
    "    timing = cpx.profiler.benchmark(F, n_repeat=n_repeat, n_warmup=n_warmup)\n",
    "    # best time from repeated runs\n",
    "    perf = np.min(timing.gpu_times)\n",
    "    print(f\"{F_name} performance = {perf:0.4f} sec\")\n",
    "\n",
    "    if F_alternative is not None:\n",
    "        timing_alt = cpx.profiler.benchmark(F_alternative, n_repeat=n_repeat, n_warmup=n_warmup)\n",
    "        perf_alt = np.min(timing_alt.gpu_times)\n",
    "        print(f\"{F_alternative_name} performance = {perf_alt:0.4f} sec\")\n",
    "        print(f\"Speedup = {perf_alt / perf:0.4f}x\")\n",
    "    else:\n",
    "        perf_alt = None\n",
    "\n",
    "    return perf, perf_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95a5b4",
   "metadata": {},
   "source": [
    "## Arithmetic Brownian motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac528a6",
   "metadata": {},
   "source": [
    "*Arithmetic Brownian motion* (which is also often called a *simple Brownian motion*) \n",
    "is among the most important stochastic processes, also known as the *Wiener process*.\n",
    "\n",
    "In its normalized form, the process $B_t$ always starts at $0$ at the moment $t = 0$ \n",
    "and evolves to time $t = T$ with zero mean and the standard deviation $\\sqrt{T}$. \n",
    "Moreover, at any two given time moments $t$ and $s$, where $t>s$, the increment \n",
    "$B_t - B_s$ is distributed normally with zero mean and standard deviation $t-s$:\n",
    "\n",
    "$B_0 = 0$\n",
    "\n",
    "$B_t - B_s \\sim \\mathcal{N}{\\left(0, t-s\\right)}$\n",
    "\n",
    "Finally, any two increments are independent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33384734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brownian_motion(nsteps, npaths):\n",
    "    dBt = np.random.randn(npaths, nsteps - 1)\n",
    "    dBt = np.insert(dBt, 0, 0.0, axis=1)  # The process starts at 0\n",
    "    Bt = np.cumsum(dBt, axis=1)\n",
    "    return Bt\n",
    "\n",
    "\n",
    "RNG_SEED = 77777  # Random seed\n",
    "N_STEPS = 100  # Number of time steps\n",
    "N_PATHS = 500  # Number of simulated paths\n",
    "\n",
    "np.random.seed(RNG_SEED)\n",
    "paths = brownian_motion(N_STEPS, N_PATHS)\n",
    "t = np.arange(N_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993c7279",
   "metadata": {},
   "source": [
    "Let's visualize how process behaves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c7e7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "\n",
    "LIGHTGREY = \"#AAA\"\n",
    "GREY = \"#777\"\n",
    "BLACK = \"#000\"\n",
    "BLUE = \"#88f\"\n",
    "DARKBLUE = \"#55a\"\n",
    "\n",
    "fig = plt.figure(figsize=(13, 6))\n",
    "ax0 = plt.subplot2grid((1, 4), (0, 0), colspan=3)\n",
    "\n",
    "ax0.grid(True, linestyle=\"--\")\n",
    "ax0.axvline(x=0, color=\"k\")\n",
    "for i in range(1, paths.shape[0]):\n",
    "    ax0.plot(t, paths[i], color=BLUE, linewidth=1)\n",
    "ax0.plot(t, paths[0], color=DARKBLUE, linewidth=4)\n",
    "ax0.plot(t, np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, -np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, 2 * np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, -2 * np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, 3 * np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.plot(t, -3 * np.sqrt(t), color=BLACK, linestyle=\":\", linewidth=2)\n",
    "ax0.annotate(r\"$\\sqrt{t}$\", xy=(50, 9), fontsize=16, fontweight=\"bold\", rotation=6, ha=\"center\", va=\"center\")\n",
    "ax0.annotate(r\"$2\\sqrt{t}$\", xy=(50, 16), fontsize=16, fontweight=\"bold\", rotation=10, ha=\"center\", va=\"center\")\n",
    "ax0.annotate(r\"$3\\sqrt{t}$\", xy=(50, 24), fontsize=16, fontweight=\"bold\", rotation=12, ha=\"center\", va=\"center\")\n",
    "ax0.set_xlabel(\"Time Steps\")\n",
    "ax0.set_title(\"Brownian motion\")\n",
    "ax0.axis(\"on\")\n",
    "ax0.set_ylim(-30, 30)\n",
    "\n",
    "x = np.linspace(-30, 30)\n",
    "ax1 = plt.subplot2grid((1, 4), (0, 3), colspan=1)\n",
    "ax1.hist(paths[:, -1], bins=29, density=True, orientation=\"horizontal\", color=BLUE, edgecolor=DARKBLUE)\n",
    "ax1.plot(norm.pdf(x, loc=0, scale=math.sqrt(N_STEPS)), x, color=BLACK)\n",
    "ax1.set_ylim(-30, 30)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax1.set_title(f\"Histogram at $t={N_STEPS}$\")\n",
    "ax1.annotate(r\"$\\mathcal{N}{\\left(0, t\\right)}$\", xy=(0.04, 0), va=\"center\", rotation=-90, fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72d6c8d",
   "metadata": {},
   "source": [
    "## Geometric Brownian motion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757419fe",
   "metadata": {},
   "source": [
    "It is a derivative process from arithmetic Brownian motion, which is useful in \n",
    "simulating non-negative stochastic processes.\n",
    "\n",
    "$S_t = S_0 \\exp \\left(\\left( \\mu - \\sigma^2 / 2 \\right) t + \\sigma B_t \\right)$\n",
    "\n",
    "Here $\\mu$ is called the *drift* and $\\sigma$ is called the *volatility*. Sometimes \n",
    "it is more useful to express the process in the *differential form*:\n",
    "\n",
    "$dS_t = \\mu S_t + \\sigma S_t dB_t$\n",
    "\n",
    "As the first order approximation, stock prices can be often modeled as the geometric \n",
    "Brownian motion (GBM). Unlike simple Brownian motion, which starts at $0$, the \n",
    "geometric Brownian motions starts at $S_0$ and never goes below $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709aebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003\n",
    "SIGMA = 0.027\n",
    "\n",
    "RNG_SEED = 77777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps\n",
    "N_PATHS = 500  # Number of simulated paths\n",
    "\n",
    "\n",
    "def brownian_motion(nsteps, npaths, mu, sigma):\n",
    "    # Differential form of the Brownian motion\n",
    "    dBt = np.random.randn(npaths, nsteps - 1) * sigma + mu\n",
    "    dBt = np.insert(dBt, 0, 0.0, axis=1)  # The process starts at 0\n",
    "\n",
    "    # Integral form of the Brownian motion\n",
    "    Bt = np.cumsum(dBt, axis=1)\n",
    "\n",
    "    return Bt\n",
    "\n",
    "\n",
    "np.random.seed(RNG_SEED)\n",
    "b_t = brownian_motion(N_STEPS, N_PATHS, MU, SIGMA)\n",
    "s_t = S0 * np.exp(b_t)\n",
    "\n",
    "print(f\"Mean stock price at t=T: {s_t[:, -1].mean():0.2f}\")\n",
    "print(f\"Standard deviation of stock price at t=T: {s_t[:, -1].std():0.2f}\")\n",
    "print(type(s_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4533e7c",
   "metadata": {},
   "source": [
    "Let's visualize $S_t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13, 6))\n",
    "ax = plt.subplot2grid((1, 1), (0, 0), colspan=1)\n",
    "for i in range(s_t.shape[0]):\n",
    "    ax.plot(s_t[i], color=BLUE, linewidth=1)\n",
    "ax.set_title(\" Stock price simulated as GBM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c7cf4",
   "metadata": {},
   "source": [
    "Let us create a GPU version of the code using CuPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41662f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvmath\n",
    "import cupy as cp\n",
    "\n",
    "RNG_SEED = 777777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps (trading days in a year)\n",
    "N_PATHS = 800000  # Number of simulated paths (large number to get a reliable estimate)\n",
    "\n",
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003  # Drift with upward trend\n",
    "SIGMA = 0.027  # Volatility\n",
    "\n",
    "\n",
    "def brownian_motion(nsteps, npaths, mu, sigma):\n",
    "    # Differential form of the Brownian motion\n",
    "    dBt = cp.empty((npaths, nsteps), dtype=cp.float32, order=\"F\")\n",
    "    dBt[:, 0] = 0.0  # The process starts at 0\n",
    "    dBt[:, 1:] = cp.random.randn(npaths, nsteps - 1) * sigma + mu\n",
    "\n",
    "    # Integral form of the Brownian motion\n",
    "    Bt = cp.cumsum(dBt, axis=1)\n",
    "\n",
    "    return Bt\n",
    "\n",
    "\n",
    "def generate_gbm_paths_cupy(npaths, nsteps, mu, sigma, s0):\n",
    "    b_t = brownian_motion(nsteps, npaths, mu, sigma)\n",
    "    paths = s0 * cp.exp(b_t)\n",
    "    return paths\n",
    "\n",
    "\n",
    "cp.random.seed(RNG_SEED)\n",
    "s_t = generate_gbm_paths_cupy(N_PATHS, N_STEPS, MU, SIGMA, S0)\n",
    "\n",
    "print(f\"Mean stock price at t=T: {s_t[:, -1].mean():0.2f}\")\n",
    "print(f\"Standard deviation of stock price at t=T: {s_t[:, -1].std():0.2f}\")\n",
    "print(type(s_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfef5ed4",
   "metadata": {},
   "source": [
    "The above code consists of a chain of primitive operations with very low arithmetic \n",
    "intensity. Each primitive operation processes an array of the shape `(N_PATHS, N_STEPS)`, \n",
    "which makes the overall workload heavily memory-bound.\n",
    "\n",
    "One of ways to improve the workload's arithmetic intensity and to make it less \n",
    "memory-bound is to implement a custom device kernel using *numba-cuda*, which will \n",
    "handle the entire Monte Carlo path from $t=0$ till $t=T$ by an individual thread. \n",
    "The total number of threads will be equal to `N_PATHS`.\n",
    "\n",
    "The nvmath-python provides device APIs for *random number generation*, which can be \n",
    "used within *numba-cuda* kernel for effective random number generation. The following \n",
    "code illustrates the implementation of the GBM using *numba-cuda* and nvmath-python's \n",
    "random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from nvmath.device import random\n",
    "import cupy as cp\n",
    "\n",
    "RNG_SEED = 777777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps (trading days in a year)\n",
    "N_PATHS = 800000  # Number of simulated paths (large number to get a reliable estimate)\n",
    "\n",
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003  # Drift with upward trend\n",
    "SIGMA = 0.027  # Volatility\n",
    "\n",
    "# Pre-compile the random number generator into IR to use alongside other device code\n",
    "compiled_rng = random.Compile(cc=None)\n",
    "\n",
    "# Set up CUDA kernel launch configuration\n",
    "threads_per_block = 32\n",
    "blocks = N_PATHS // threads_per_block\n",
    "nthreads = threads_per_block * blocks\n",
    "print(f\"blocks: {blocks}, threads_per_block: {threads_per_block}, nthreads: {nthreads}\")\n",
    "\n",
    "# Allocate space for random states\n",
    "states = random.StatesPhilox4_32_10(nthreads)\n",
    "\n",
    "\n",
    "# RNG initialization kernel\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def init_rng_gpu(states, seed):\n",
    "    idx = cuda.grid(1)\n",
    "    random.init(seed, idx, 0, states[idx])\n",
    "\n",
    "\n",
    "# GBM path generation kernel. Note that the random numbers are generated\n",
    "# as they are needed, unlike for the NumPy/CuPy implementation where they are\n",
    "# generated upfront and stored.\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def generate_gbm_paths_nvmath(states, paths, nsteps, mu, sigma, s0):\n",
    "    mu = paths.dtype.type(mu)\n",
    "    sigma = paths.dtype.type(sigma)\n",
    "    s0 = paths.dtype.type(s0)\n",
    "\n",
    "    idx = cuda.grid(1)\n",
    "    if idx >= paths.shape[0]:\n",
    "        return\n",
    "\n",
    "    # Each thread generates one path in the time domain\n",
    "    paths[idx, 0] = s0\n",
    "\n",
    "    # Consume a single normal variate at a time\n",
    "    for i in range(1, nsteps):\n",
    "        z = random.normal(states[idx])\n",
    "        z = mu + sigma * z\n",
    "        paths[idx, i] = paths[idx, i - 1] * math.exp(z)\n",
    "\n",
    "\n",
    "# Allocate space for paths\n",
    "paths_gpu = cp.empty((N_PATHS, N_STEPS), dtype=cp.float32, order=\"F\")\n",
    "\n",
    "# Initialize RNG states\n",
    "init_rng_gpu[blocks, threads_per_block](states, RNG_SEED)\n",
    "\n",
    "# Generate GBM paths on GPU\n",
    "generate_gbm_paths_nvmath[blocks, threads_per_block](states, paths_gpu, N_STEPS, MU, SIGMA, S0)\n",
    "\n",
    "print(f\"Mean stock price at t=T: {paths_gpu[:, -1].mean():0.2f}\")\n",
    "print(f\"Standard deviation of stock price at t=T: {paths_gpu[:, -1].std():0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407111ad",
   "metadata": {},
   "source": [
    "Now, let's benchmark the nvmath-python implementation and compare to CuPy implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd57a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    lambda: generate_gbm_paths_nvmath[blocks, threads_per_block](states, paths_gpu, N_STEPS, MU, SIGMA, S0),\n",
    "    \"nvmath-python\",\n",
    "    lambda: generate_gbm_paths_cupy(N_PATHS, N_STEPS, MU, SIGMA, S0),\n",
    "    \"CuPy\",\n",
    "    n_repeat=5,\n",
    "    n_warmup=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a525e68",
   "metadata": {},
   "source": [
    "Now let us modify the generation kernel to leverage the fact that the Philox4_32_10 \n",
    "generator returns 4 variates at a time allowing to produce 4 time steps in a single \n",
    "loop iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "from nvmath.device import random\n",
    "import cupy as cp\n",
    "\n",
    "RNG_SEED = 777777  # Random seed\n",
    "N_STEPS = 252  # Number of time steps (trading days in a year)\n",
    "N_PATHS = 800000  # Number of simulated paths (large number to get a reliable estimate)\n",
    "\n",
    "S0 = 100.0  # Initial stock price\n",
    "MU = 0.003  # Drift with upward trend\n",
    "SIGMA = 0.027  # Volatility\n",
    "\n",
    "# Pre-compile the random number generator into IR to use alongside other device code\n",
    "compiled_rng = random.Compile(cc=None)\n",
    "\n",
    "# Set up CUDA kernel launch configuration\n",
    "threads_per_block = 32\n",
    "blocks = N_PATHS // threads_per_block\n",
    "nthreads = threads_per_block * blocks\n",
    "print(f\"blocks: {blocks}, threads_per_block: {threads_per_block}, nthreads: {nthreads}\")\n",
    "\n",
    "# Allocate space for random states\n",
    "states = random.StatesPhilox4_32_10(nthreads)\n",
    "\n",
    "\n",
    "# RNG initialization kernel\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def init_rng_gpu(states, seed):\n",
    "    idx = cuda.grid(1)\n",
    "    random.init(seed, idx, 0, states[idx])\n",
    "\n",
    "\n",
    "@cuda.jit(link=compiled_rng.files, extensions=compiled_rng.extension)\n",
    "def generate_gbm_paths_gpu(states, paths, nsteps, mu, sigma, s0):\n",
    "    mu = paths.dtype.type(mu)\n",
    "    sigma = paths.dtype.type(sigma)\n",
    "    s0 = paths.dtype.type(s0)\n",
    "\n",
    "    idx = cuda.grid(1)\n",
    "    if idx >= paths.shape[0]:\n",
    "        return\n",
    "\n",
    "    # Each thread generates one path in the time domain\n",
    "    paths[idx, 0] = s0\n",
    "\n",
    "    # Consume 4 normal variates at a time for better throughput\n",
    "    for i in range(1, nsteps, 4):\n",
    "        v = random.normal4(states[idx])  # Returned as float32x4 type\n",
    "        vals = v.x, v.y, v.z, v.w  # Decompose into a tuple of float32\n",
    "        # Process a chunk of 4 time steps, use min() to avoid out-of-bounds access\n",
    "        for j in range(i, min(i + 4, nsteps)):\n",
    "            paths[idx, j] = paths[idx, j - 1] * math.exp(mu + sigma * vals[j - i])\n",
    "\n",
    "\n",
    "# Allocate space for paths\n",
    "paths_gpu = cp.empty((N_PATHS, N_STEPS), dtype=cp.float32, order=\"F\")\n",
    "\n",
    "# Initialize RNG states\n",
    "init_rng_gpu[blocks, threads_per_block](states, RNG_SEED)\n",
    "\n",
    "# Generate GBM paths on GPU\n",
    "generate_gbm_paths_nvmath[blocks, threads_per_block](states, paths_gpu, N_STEPS, MU, SIGMA, S0)\n",
    "\n",
    "print(f\"Mean stock price at t=T: {paths_gpu[:, -1].mean():0.2f}\")\n",
    "print(f\"Standard deviation of stock price at t=T: {paths_gpu[:, -1].std():0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(\n",
    "    lambda: generate_gbm_paths_nvmath[blocks, threads_per_block](states, paths_gpu, N_STEPS, MU, SIGMA, S0),\n",
    "    \"nvmath-python\",\n",
    "    lambda: generate_gbm_paths_cupy(N_PATHS, N_STEPS, MU, SIGMA, S0),\n",
    "    \"CuPy\",\n",
    "    n_repeat=5,\n",
    "    n_warmup=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "takeaways_device_api",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#76B900; color:#ffffff; padding:12px; border-radius:8px; max-width:80%; width:auto; margin:0 auto;\">\n",
    "<h3 style=\"margin-top:0; color:#ffffff\">Takeaways</h3>\n",
    "\n",
    "- nvmath-python device APIs allow direct integration within custom numba-cuda kernels, dramatically reducing implementation costs of math-intense kernels.\n",
    "- Kernel fusion eliminates intermediate array allocations and memory transfers, significantly improving overall arithmetic intensity.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
